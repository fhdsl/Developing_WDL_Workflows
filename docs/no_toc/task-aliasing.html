<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 7 Task Aliasing | Developing WDL Workflows</title>
  <meta name="description" content="Description about Course/Book." />
  <meta name="generator" content="bookdown 0.24 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 7 Task Aliasing | Developing WDL Workflows" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="Description about Course/Book." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 7 Task Aliasing | Developing WDL Workflows" />
  
  <meta name="twitter:description" content="Description about Course/Book." />
  




  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  <link rel="shortcut icon" href="assets/dasl_favicon.ico" type="image/x-icon" />
<link rel="prev" href="parallelization-via-arrays.html"/>
<link rel="next" href="optional-types.html"/>
<script src="libs/header-attrs-2.10/header-attrs.js"></script>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.0.1/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0.1/anchor-sections.js"></script>
 
<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-N5Q1FEXP22"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-N5Q1FEXP22');
</script>





<link rel="stylesheet" href="assets/style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<a href="https://hutchdatascience.org/" target="_blank"><img src="assets/big-dasl-stacked.png" style="width: 80%; padding-left: 34px; padding-top: 8px;"</a>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>About this Course</a>
<ul>
<li class="chapter" data-level="0.1" data-path="index.html"><a href="index.html#target-audience"><i class="fa fa-check"></i><b>0.1</b> Target Audience</a>
<ul>
<li class="chapter" data-level="0.1.1" data-path="index.html"><a href="index.html#relevant-resources"><i class="fa fa-check"></i><b>0.1.1</b> Relevant Resources</a></li>
</ul></li>
<li class="chapter" data-level="0.2" data-path="index.html"><a href="index.html#why-wdl"><i class="fa fa-check"></i><b>0.2</b> Why WDL?</a>
<ul>
<li class="chapter" data-level="0.2.1" data-path="index.html"><a href="index.html#wdl-pros"><i class="fa fa-check"></i><b>0.2.1</b> WDL Pros</a></li>
<li class="chapter" data-level="0.2.2" data-path="index.html"><a href="index.html#wdl-cons"><i class="fa fa-check"></i><b>0.2.2</b> WDL Cons</a></li>
</ul></li>
<li class="chapter" data-level="0.3" data-path="index.html"><a href="index.html#curriculum"><i class="fa fa-check"></i><b>0.3</b> Curriculum</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="introduction-to-wdl.html"><a href="introduction-to-wdl.html"><i class="fa fa-check"></i><b>1</b> Introduction to WDL</a>
<ul>
<li class="chapter" data-level="1.1" data-path="introduction-to-wdl.html"><a href="introduction-to-wdl.html#introduction"><i class="fa fa-check"></i><b>1.1</b> Introduction</a></li>
<li class="chapter" data-level="1.2" data-path="introduction-to-wdl.html"><a href="introduction-to-wdl.html#review-of-basic-wdl-syntax"><i class="fa fa-check"></i><b>1.2</b> Review of basic WDL syntax</a></li>
<li class="chapter" data-level="1.3" data-path="introduction-to-wdl.html"><a href="introduction-to-wdl.html#using-jsons-to-control-workflow-inputs"><i class="fa fa-check"></i><b>1.3</b> Using JSONs to control workflow inputs</a></li>
<li class="chapter" data-level="1.4" data-path="introduction-to-wdl.html"><a href="introduction-to-wdl.html#running-wdl-via-a-computing-engine"><i class="fa fa-check"></i><b>1.4</b> Running WDL via a computing engine</a>
<ul>
<li class="chapter" data-level="1.4.1" data-path="introduction-to-wdl.html"><a href="introduction-to-wdl.html#installing-docker"><i class="fa fa-check"></i><b>1.4.1</b> Installing Docker</a></li>
<li class="chapter" data-level="1.4.2" data-path="introduction-to-wdl.html"><a href="introduction-to-wdl.html#installing-miniwdl"><i class="fa fa-check"></i><b>1.4.2</b> Installing miniwdl</a></li>
<li class="chapter" data-level="1.4.3" data-path="introduction-to-wdl.html"><a href="introduction-to-wdl.html#launching-a-workflow-locally-with-miniwdl"><i class="fa fa-check"></i><b>1.4.3</b> Launching a workflow locally with miniwdl</a></li>
<li class="chapter" data-level="1.4.4" data-path="introduction-to-wdl.html"><a href="introduction-to-wdl.html#troubleshooting"><i class="fa fa-check"></i><b>1.4.4</b> Troubleshooting</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="defining-a-workflow-plan.html"><a href="defining-a-workflow-plan.html"><i class="fa fa-check"></i><b>2</b> Defining a workflow plan</a>
<ul>
<li class="chapter" data-level="2.1" data-path="defining-a-workflow-plan.html"><a href="defining-a-workflow-plan.html#somatic-mutation-calling-workflow"><i class="fa fa-check"></i><b>2.1</b> Somatic mutation calling workflow</a></li>
<li class="chapter" data-level="2.2" data-path="defining-a-workflow-plan.html"><a href="defining-a-workflow-plan.html#workflow-testing-strategy"><i class="fa fa-check"></i><b>2.2</b> Workflow testing strategy</a></li>
<li class="chapter" data-level="2.3" data-path="defining-a-workflow-plan.html"><a href="defining-a-workflow-plan.html#test-samples"><i class="fa fa-check"></i><b>2.3</b> Test samples</a>
<ul>
<li class="chapter" data-level="2.3.1" data-path="defining-a-workflow-plan.html"><a href="defining-a-workflow-plan.html#tumor-1-hcc4006"><i class="fa fa-check"></i><b>2.3.1</b> Tumor 1 : HCC4006</a></li>
<li class="chapter" data-level="2.3.2" data-path="defining-a-workflow-plan.html"><a href="defining-a-workflow-plan.html#tumor-2-calu1"><i class="fa fa-check"></i><b>2.3.2</b> Tumor 2 : CALU1</a></li>
<li class="chapter" data-level="2.3.3" data-path="defining-a-workflow-plan.html"><a href="defining-a-workflow-plan.html#normal-molm13"><i class="fa fa-check"></i><b>2.3.3</b> Normal : MOLM13</a></li>
<li class="chapter" data-level="2.3.4" data-path="defining-a-workflow-plan.html"><a href="defining-a-workflow-plan.html#test-data-details"><i class="fa fa-check"></i><b>2.3.4</b> Test data details</a></li>
<li class="chapter" data-level="2.3.5" data-path="defining-a-workflow-plan.html"><a href="defining-a-workflow-plan.html#access-to-files"><i class="fa fa-check"></i><b>2.3.5</b> Access to files</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="the-first-task.html"><a href="the-first-task.html"><i class="fa fa-check"></i><b>3</b> The first task</a>
<ul>
<li class="chapter" data-level="3.1" data-path="the-first-task.html"><a href="the-first-task.html#inputs"><i class="fa fa-check"></i><b>3.1</b> Inputs</a>
<ul>
<li class="chapter" data-level="3.1.1" data-path="the-first-task.html"><a href="the-first-task.html#referencing-inputs-in-the-command-section"><i class="fa fa-check"></i><b>3.1.1</b> Referencing inputs in the command section</a></li>
<li class="chapter" data-level="3.1.2" data-path="the-first-task.html"><a href="the-first-task.html#file-localization"><i class="fa fa-check"></i><b>3.1.2</b> File localization</a></li>
<li class="chapter" data-level="3.1.3" data-path="the-first-task.html"><a href="the-first-task.html#private-variables"><i class="fa fa-check"></i><b>3.1.3</b> Private variables</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="the-first-task.html"><a href="the-first-task.html#runtime-attributes"><i class="fa fa-check"></i><b>3.2</b> Runtime attributes</a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="the-first-task.html"><a href="the-first-task.html#docker-images-and-containers"><i class="fa fa-check"></i><b>3.2.1</b> Docker images and containers</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="the-first-task.html"><a href="the-first-task.html#outputs"><i class="fa fa-check"></i><b>3.3</b> Outputs</a></li>
<li class="chapter" data-level="3.4" data-path="the-first-task.html"><a href="the-first-task.html#the-whole-task"><i class="fa fa-check"></i><b>3.4</b> The whole task</a></li>
<li class="chapter" data-level="3.5" data-path="the-first-task.html"><a href="the-first-task.html#putting-the-workflow-together"><i class="fa fa-check"></i><b>3.5</b> Putting the workflow together</a></li>
<li class="chapter" data-level="3.6" data-path="the-first-task.html"><a href="the-first-task.html#testing-your-first-task"><i class="fa fa-check"></i><b>3.6</b> Testing your first task</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="connecting-multiple-tasks-together-in-a-linear-chain.html"><a href="connecting-multiple-tasks-together-in-a-linear-chain.html"><i class="fa fa-check"></i><b>4</b> Connecting multiple tasks together in a linear chain</a>
<ul>
<li class="chapter" data-level="4.1" data-path="connecting-multiple-tasks-together-in-a-linear-chain.html"><a href="connecting-multiple-tasks-together-in-a-linear-chain.html#how-to-connect-tasks-together-in-a-workflow"><i class="fa fa-check"></i><b>4.1</b> How to connect tasks together in a workflow</a></li>
<li class="chapter" data-level="4.2" data-path="connecting-multiple-tasks-together-in-a-linear-chain.html"><a href="connecting-multiple-tasks-together-in-a-linear-chain.html#writing-markduplicates-task"><i class="fa fa-check"></i><b>4.2</b> Writing <code>MarkDuplicates</code> task</a>
<ul>
<li class="chapter" data-level="4.2.1" data-path="connecting-multiple-tasks-together-in-a-linear-chain.html"><a href="connecting-multiple-tasks-together-in-a-linear-chain.html#input"><i class="fa fa-check"></i><b>4.2.1</b> Input</a></li>
<li class="chapter" data-level="4.2.2" data-path="connecting-multiple-tasks-together-in-a-linear-chain.html"><a href="connecting-multiple-tasks-together-in-a-linear-chain.html#private-variables-in-the-task"><i class="fa fa-check"></i><b>4.2.2</b> Private variables in the task</a></li>
<li class="chapter" data-level="4.2.3" data-path="connecting-multiple-tasks-together-in-a-linear-chain.html"><a href="connecting-multiple-tasks-together-in-a-linear-chain.html#command"><i class="fa fa-check"></i><b>4.2.3</b> Command</a></li>
<li class="chapter" data-level="4.2.4" data-path="connecting-multiple-tasks-together-in-a-linear-chain.html"><a href="connecting-multiple-tasks-together-in-a-linear-chain.html#runtime-and-output"><i class="fa fa-check"></i><b>4.2.4</b> Runtime and Output</a></li>
<li class="chapter" data-level="4.2.5" data-path="connecting-multiple-tasks-together-in-a-linear-chain.html"><a href="connecting-multiple-tasks-together-in-a-linear-chain.html#testing-the-workflow"><i class="fa fa-check"></i><b>4.2.5</b> Testing the workflow</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="connecting-multiple-tasks-together-in-a-linear-chain.html"><a href="connecting-multiple-tasks-together-in-a-linear-chain.html#the-rest-of-the-linear-chain-workflow"><i class="fa fa-check"></i><b>4.3</b> The rest of the linear chain workflow</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="organizing-variables-via-structs.html"><a href="organizing-variables-via-structs.html"><i class="fa fa-check"></i><b>5</b> Organizing variables via Structs</a></li>
<li class="chapter" data-level="6" data-path="parallelization-via-arrays.html"><a href="parallelization-via-arrays.html"><i class="fa fa-check"></i><b>6</b> Parallelization via Arrays</a>
<ul>
<li class="chapter" data-level="6.1" data-path="parallelization-via-arrays.html"><a href="parallelization-via-arrays.html#the-array-type"><i class="fa fa-check"></i><b>6.1</b> The array type</a></li>
<li class="chapter" data-level="6.2" data-path="parallelization-via-arrays.html"><a href="parallelization-via-arrays.html#scattered-tasks"><i class="fa fa-check"></i><b>6.2</b> Scattered tasks</a>
<ul>
<li class="chapter" data-level="6.2.1" data-path="parallelization-via-arrays.html"><a href="parallelization-via-arrays.html#troubleshooting-1"><i class="fa fa-check"></i><b>6.2.1</b> Troubleshooting</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="parallelization-via-arrays.html"><a href="parallelization-via-arrays.html#making-our-workflow-run-on-multiple-samples-at-once-using-scattered-tasks-and-arrays"><i class="fa fa-check"></i><b>6.3</b> Making our workflow run on multiple samples at once using scattered tasks and arrays</a></li>
<li class="chapter" data-level="6.4" data-path="parallelization-via-arrays.html"><a href="parallelization-via-arrays.html#referencing-an-array-in-a-task"><i class="fa fa-check"></i><b>6.4</b> Referencing an array in a task</a></li>
<li class="chapter" data-level="6.5" data-path="parallelization-via-arrays.html"><a href="parallelization-via-arrays.html#the-workflow-so-far"><i class="fa fa-check"></i><b>6.5</b> The workflow so far</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="task-aliasing.html"><a href="task-aliasing.html"><i class="fa fa-check"></i><b>7</b> Task Aliasing</a>
<ul>
<li class="chapter" data-level="7.1" data-path="task-aliasing.html"><a href="task-aliasing.html#aliasing-your-first-task"><i class="fa fa-check"></i><b>7.1</b> Aliasing your first task</a></li>
<li class="chapter" data-level="7.2" data-path="task-aliasing.html"><a href="task-aliasing.html#aliasing-other-tasks"><i class="fa fa-check"></i><b>7.2</b> Aliasing other tasks</a></li>
<li class="chapter" data-level="7.3" data-path="task-aliasing.html"><a href="task-aliasing.html#paired-tumor-normal-calling"><i class="fa fa-check"></i><b>7.3</b> Paired tumor normal calling</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="optional-types.html"><a href="optional-types.html"><i class="fa fa-check"></i><b>8</b> Optional types</a>
<ul>
<li class="chapter" data-level="8.1" data-path="optional-types.html"><a href="optional-types.html#optional-inputs"><i class="fa fa-check"></i><b>8.1</b> Optional inputs</a></li>
<li class="chapter" data-level="8.2" data-path="optional-types.html"><a href="optional-types.html#optional-outputs"><i class="fa fa-check"></i><b>8.2</b> Optional outputs</a>
<ul>
<li class="chapter" data-level="8.2.1" data-path="optional-types.html"><a href="optional-types.html#declaring-a-tasks-output-to-be-optional"><i class="fa fa-check"></i><b>8.2.1</b> Declaring a task’s output to be optional</a></li>
<li class="chapter" data-level="8.2.2" data-path="optional-types.html"><a href="optional-types.html#making-an-entire-task-optional"><i class="fa fa-check"></i><b>8.2.2</b> Making an entire task optional</a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="optional-types.html"><a href="optional-types.html#the-final-workflow"><i class="fa fa-check"></i><b>8.3</b> The final workflow</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="optimization.html"><a href="optimization.html"><i class="fa fa-check"></i><b>9</b> Optimization</a>
<ul>
<li class="chapter" data-level="9.1" data-path="optimization.html"><a href="optimization.html#common-optimizingparallelizing-methods"><i class="fa fa-check"></i><b>9.1</b> Common optimizing/parallelizing methods</a>
<ul>
<li class="chapter" data-level="9.1.1" data-path="optimization.html"><a href="optimization.html#memory-optimization"><i class="fa fa-check"></i><b>9.1.1</b> Memory optimization</a></li>
<li class="chapter" data-level="9.1.2" data-path="optimization.html"><a href="optimization.html#embarrassingly-parallel-scatter-gather"><i class="fa fa-check"></i><b>9.1.2</b> Embarrassingly Parallel Scatter-Gather</a></li>
<li class="chapter" data-level="9.1.3" data-path="optimization.html"><a href="optimization.html#multithreading-shared-memory-parallelism"><i class="fa fa-check"></i><b>9.1.3</b> Multithreading (Shared-Memory Parallelism)</a></li>
<li class="chapter" data-level="9.1.4" data-path="optimization.html"><a href="optimization.html#multiprocessing-distributed-memory-parallelism"><i class="fa fa-check"></i><b>9.1.4</b> Multiprocessing (Distributed-Memory Parallelism)</a></li>
<li class="chapter" data-level="9.1.5" data-path="optimization.html"><a href="optimization.html#graphical-processing-units-gpus"><i class="fa fa-check"></i><b>9.1.5</b> Graphical Processing Units (GPUs)</a></li>
</ul></li>
<li class="chapter" data-level="9.2" data-path="optimization.html"><a href="optimization.html#scatter-gather-on-chromosomes"><i class="fa fa-check"></i><b>9.2</b> Scatter-Gather on chromosomes</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="appendix-backends-and-executors.html"><a href="appendix-backends-and-executors.html"><i class="fa fa-check"></i><b>10</b> Appendix: Backends and Executors</a>
<ul>
<li class="chapter" data-level="10.1" data-path="appendix-backends-and-executors.html"><a href="appendix-backends-and-executors.html#commonly-used-runtime-attributes"><i class="fa fa-check"></i><b>10.1</b> Commonly used runtime attributes</a></li>
<li class="chapter" data-level="10.2" data-path="appendix-backends-and-executors.html"><a href="appendix-backends-and-executors.html#general-advice"><i class="fa fa-check"></i><b>10.2</b> General advice</a></li>
<li class="chapter" data-level="10.3" data-path="appendix-backends-and-executors.html"><a href="appendix-backends-and-executors.html#executor-specific-notes"><i class="fa fa-check"></i><b>10.3</b> Executor-specific notes</a>
<ul>
<li class="chapter" data-level="10.3.1" data-path="appendix-backends-and-executors.html"><a href="appendix-backends-and-executors.html#cromwell"><i class="fa fa-check"></i><b>10.3.1</b> Cromwell</a></li>
<li class="chapter" data-level="10.3.2" data-path="appendix-backends-and-executors.html"><a href="appendix-backends-and-executors.html#miniwdl"><i class="fa fa-check"></i><b>10.3.2</b> miniwdl</a></li>
</ul></li>
<li class="chapter" data-level="10.4" data-path="appendix-backends-and-executors.html"><a href="appendix-backends-and-executors.html#backend-specific-notes"><i class="fa fa-check"></i><b>10.4</b> Backend-specific notes</a>
<ul>
<li class="chapter" data-level="10.4.1" data-path="appendix-backends-and-executors.html"><a href="appendix-backends-and-executors.html#hpcs"><i class="fa fa-check"></i><b>10.4.1</b> HPCs</a></li>
<li class="chapter" data-level="10.4.2" data-path="appendix-backends-and-executors.html"><a href="appendix-backends-and-executors.html#gcpterra"><i class="fa fa-check"></i><b>10.4.2</b> GCP/Terra</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="about-the-authors.html"><a href="about-the-authors.html"><i class="fa fa-check"></i>About the Authors</a></li>
<li class="chapter" data-level="11" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i><b>11</b> References</a></li>
<li class="divider"></li>
<p style="text-align:center;"> <a href="https://github.com/jhudsl/OTTR_Template" target="blank" > This content was published with</a> <a href="https://bookdown.org/" target="blank"> bookdown by: </a> </p>
<p style="text-align:center;"> <a href="https://hutchdatascience.org/"> The Fred Hutch Data Science Lab </a></p>
<p style="text-align:center; font-size: 12px;"> <a href="https://github.com/rstudio4edu/rstudio4edu-book/"> Style adapted from: rstudio4edu-book </a> <a href ="https://creativecommons.org/licenses/by/2.0/"> (CC-BY 2.0) </a></p>
<p style="padding-left: 40px;"><div class="trapezoid" style = "padding-left: 40px;"><span>  <a href="https://forms.gle/W6Mg4rzuMK6Yk3Am8"> Click here to provide feedback</a> <img src="assets/itcr_arrow.png" style=" width: 10%" ></span></div></p>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Developing WDL Workflows</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<head>
  <meta name="viewport" content="width=device-width,minimum-scale=1.0,maximum-scale=10.0,initial-scale=1.0">
  <!--script src="https://kit.fontawesome.com/6a26f47516.js"></script-->
  <!--<script src="assets/hideOutput.js"></script>-->
  <link href="assets/style.css" rel="stylesheet">
</head>
        


<div class="hero-image-container"> 
  <img class= "hero-image" src="assets/dasl_thin_main_image.png">
</div>
<div id="task-aliasing" class="section level1" number="7">
<h1><span class="header-section-number">Chapter 7</span> Task Aliasing</h1>
<p>Right now, we have developed our workflow for only tumor samples of a patient, but our mutation caller Mutect2 performs best when each tumor is matched with a normal sample. Therefore, in order to make best use of Mutect2, we want to run a similar analysis on the normal samples as well, using tasks such as BwaMem, MarkDuplicates, and ApplyBaseRecalibrator. We could write new tasks for the normal samples, but they are run exactly the same as the tumor samples: we would like to reuse our existing tasks for these tumor samples.</p>
<p>WDL has a feature that allows you to reuse the same task repeatedly through your workflow: <strong>task aliasing</strong>.
Task aliasing allows for the re-use of task definitions within the same workflow under different names, or “aliases”. For example, our task for alignment, “BwaMem”, can be aliased for both tumor and normal samples. This way, you don’t need to copy and paste the same task definition multiple times, and when you modify the the task definition, all aliases will be updated.</p>
<div id="aliasing-your-first-task" class="section level2" number="7.1">
<h2><span class="header-section-number">7.1</span> Aliasing your first task</h2>
<p>We first demonstrate task aliasing for tumor-normal matched somatic mutation calling in which we use the same normal sample for both tumor samples. This implies that we have taken multiple tumor samples from the same patient, and we’re comparing all of them against a single normal sample. This is easy to write, but not a very common analysis. After this example, we follow up with a more sophisticated tumor-normal matched somatic mutation calling in which each patient has unique paired tumor-normal samples. This is the popular way of calling somatic mutation.</p>
<p>You can only alias a task that is already defined, so we will start with aliasing the BwaMem task for normal samples rather than writing a new BwaMem task specifically for normal samples. We want to do this so it can run this task on the “normal” samples and store them separately.</p>
<p>First, make sure that in your workflow input, you reference to the normal sample as input.</p>
<pre><code>workflow mutation_calling {
  input {
    ...
    File normalFastq
...
  }</code></pre>
<p>Then, you need to call the task you want to alias and use <code>as</code> to the <code>alias_of_your_choice</code>. Within the task, you need to make sure that all the inputs reflect the new variable, so <code>input_fastq</code> is directed to <code>normalFastq</code>.</p>
<pre><code>  call BwaMem as normalBwaMem {
    input:
      input_fastq = normalFastq,
      refGenome = refGenome
  }</code></pre>
<p>In the output of the workflow, you also want to make sure that in you are saving the appropriate outputs to reflect the task alias.</p>
<pre><code>output {
  File normalalignedBamSorted = normalBwaMem.analysisReadySorted
}</code></pre>
</div>
<div id="aliasing-other-tasks" class="section level2" number="7.2">
<h2><span class="header-section-number">7.2</span> Aliasing other tasks</h2>
<p>We can do this for the other two tasks in our workflow as well for the normal sample:</p>
<pre><code>call MarkDuplicates as normalMarkDuplicates {
    input:
      input_bam = normalBwaMem.analysisReadySorted
  }

  call ApplyBaseRecalibrator as normalApplyBaseRecalibrator {
    input:
      input_bam = normalMarkDuplicates.markDuplicates_bam,
      input_bam_index = normalMarkDuplicates.markDuplicates_bai,
      dbSNP_vcf = dbSNP_vcf,
      dbSNP_vcf_index = dbSNP_vcf_index,
      known_indels_sites_VCFs = known_indels_sites_VCFs,
      known_indels_sites_indices = known_indels_sites_indices,
      refGenome = refGenome
  }</code></pre>
<p>After adding these steps to the workflow, we will have our normal sample aligned and recalibrated. Together with the tumor sample, we can use the paired version of Mutect2 via the new <code>Mutect2Paired</code> task.</p>
<details>
<summary>
<b>The workflow so far using the same normal sample for tumor-normal mutation calling. </b>
</summary>
<pre><code>version 1.0
## WDL 101 example workflow
## 
## This WDL workflow is intended to be used along with the WDL 101 docs. 
## This workflow should be used for inspiration purposes only. 
##
## We use three samples 
## Samples:
## MOLM13: Normal sample
## CALU1: KRAS G12C mutant
## HCC4006: EGFR Ex19 deletion mutant 
##
## Input requirements:
## - combined fastq files for chromosome 12 and 7 +/- 200bp around the sites of mutation only
##
## Output Files:
## - An aligned bam for all 3 samples (with duplicates marked and base quality recalibrated)
## 
## Workflow developed by Sitapriya Moorthi, Chris Lo and Taylor Firman @ Fred Hutch and Ash (Aisling) O&#39;Farrell @ UCSC LMD: 02/28/24 for use @ Fred Hutch.

struct referenceGenome {
    File ref_fasta
    File ref_fasta_index
    File ref_dict
    File ref_amb
    File ref_ann
    File ref_bwt
    File ref_pac
    File ref_sa
    String ref_name
}


workflow mutation_calling {
  input {
    Array[File] tumorSamples
    File normalFastq

    referenceGenome refGenome
    
    # Files for specific tools
    File dbSNP_vcf
    File dbSNP_vcf_index
    File known_indels_sites_VCFs
    File known_indels_sites_indices
    File af_only_gnomad
    File af_only_gnomad_index

    # Annovar options
    String annovar_protocols
    String annovar_operation
  }

  # First, process the non-tumor normal sample
  call BwaMem as normalBwaMem {
    input:
      input_fastq = normalFastq,
      refGenome = refGenome
  }
  
  call MarkDuplicates as normalMarkDuplicates {
    input:
      input_bam = normalBwaMem.analysisReadySorted
  }

  call ApplyBaseRecalibrator as normalApplyBaseRecalibrator {
    input:
      input_bam = normalMarkDuplicates.markDuplicates_bam,
      input_bam_index = normalMarkDuplicates.markDuplicates_bai,
      dbSNP_vcf = dbSNP_vcf,
      dbSNP_vcf_index = dbSNP_vcf_index,
      known_indels_sites_VCFs = known_indels_sites_VCFs,
      known_indels_sites_indices = known_indels_sites_indices,
      refGenome = refGenome
  }
 
  # Scatter for &quot;tumor&quot; samples   
  scatter (tumorSample in tumorSamples) {
    call BwaMem as tumorBwaMem {
      input:
        input_fastq = tumorSample,
        refGenome = refGenome
    }
    
    call MarkDuplicates as tumorMarkDuplicates {
      input:
        input_bam = tumorBwaMem.analysisReadySorted
    }

    call ApplyBaseRecalibrator as tumorApplyBaseRecalibrator{
      input:
        input_bam = tumorMarkDuplicates.markDuplicates_bam,
        input_bam_index = tumorMarkDuplicates.markDuplicates_bai,
        dbSNP_vcf = dbSNP_vcf,
        dbSNP_vcf_index = dbSNP_vcf_index,
        known_indels_sites_VCFs = known_indels_sites_VCFs,
        known_indels_sites_indices = known_indels_sites_indices,
        refGenome = refGenome
      }

    call Mutect2Paired {
      input:
        tumor_bam = tumorApplyBaseRecalibrator.recalibrated_bam,
        tumor_bam_index = tumorApplyBaseRecalibrator.recalibrated_bai,
        normal_bam = normalApplyBaseRecalibrator.recalibrated_bam,
        normal_bam_index = normalApplyBaseRecalibrator.recalibrated_bai,
        refGenome = refGenome,
        genomeReference = af_only_gnomad,
        genomeReferenceIndex = af_only_gnomad_index
    }

  call annovar {
    input:
      input_vcf = Mutect2Paired.output_vcf,
      ref_name = refGenome.ref_name,
      annovar_operation = annovar_operation,
      annovar_protocols = annovar_protocols
  }
}

  output {
    Array[File] tumoralignedBamSorted = tumorBwaMem.analysisReadySorted
    Array[File] tumorMarkDuplicates_bam = tumorMarkDuplicates.markDuplicates_bam
    Array[File] tumorMarkDuplicates_bai = tumorMarkDuplicates.markDuplicates_bai
    Array[File] tumoranalysisReadyBam = tumorApplyBaseRecalibrator.recalibrated_bam 
    Array[File] tumoranalysisReadyIndex = tumorApplyBaseRecalibrator.recalibrated_bai
    File normalalignedBamSorted = normalBwaMem.analysisReadySorted
    File normalmarkDuplicates_bam = normalMarkDuplicates.markDuplicates_bam
    File normalmarkDuplicates_bai = normalMarkDuplicates.markDuplicates_bai
    File normalanalysisReadyBam = normalApplyBaseRecalibrator.recalibrated_bam 
    File normalanalysisReadyIndex = normalApplyBaseRecalibrator.recalibrated_bai
    Array[File] Mutect2Paired_Vcf = Mutect2Paired.output_vcf
    Array[File] Mutect2Paired_VcfIndex = Mutect2Paired.output_vcf_index
    Array[File] Mutect2Paired_AnnotatedVcf = annovar.output_annotated_vcf
    Array[File] Mutect2Paired_AnnotatedTable = annovar.output_annotated_table
  }

  parameter_meta {
    tumorSamples: &quot;Tumor .fastq, one sample per .fastq file (expects Illumina)&quot;
    normalFastq: &quot;Non-tumor .fastq (expects Illumina)&quot;

    dbSNP_vcf: &quot;dbSNP VCF for mutation calling&quot;
    dbSNP_vcf_index: &quot;dbSNP VCF index&quot;
    known_indels_sites_VCFs: &quot;Known indel site VCF for mutation calling&quot;
    known_indels_sites_indices: &quot;Known indel site VCF indicies&quot;
    af_only_gnomad: &quot;gnomAD population allele fraction for mutation calling&quot;
    af_only_gnomad_index: &quot;gnomAD population allele fraction index&quot;

    annovar_protocols: &quot;annovar protocols: see https://annovar.openbioinformatics.org/en/latest/user-guide/startup&quot;
    annovar_operation: &quot;annovar operation: see https://annovar.openbioinformatics.org/en/latest/user-guide/startup&quot;
  }
}

####################
# Task definitions #
####################

# Align fastq file to the reference genome
task BwaMem {
  input {
    File input_fastq
    referenceGenome refGenome
  }
  
  String base_file_name = basename(input_fastq, &quot;.fastq&quot;)
  String ref_fasta_local = basename(refGenome.ref_fasta)

  String read_group_id = &quot;ID:&quot; + base_file_name
  String sample_name = &quot;SM:&quot; + base_file_name
  String platform_info = &quot;PL:illumina&quot;


  command &lt;&lt;&lt;
    set -eo pipefail

    mv &quot;~{refGenome.ref_fasta}&quot; .
    mv &quot;~{refGenome.ref_fasta_index}&quot; .
    mv &quot;~{refGenome.ref_dict}&quot; .
    mv &quot;~{refGenome.ref_amb}&quot; .
    mv &quot;~{refGenome.ref_ann}&quot; .
    mv &quot;~{refGenome.ref_bwt}&quot; .
    mv &quot;~{refGenome.ref_pac}&quot; .
    mv &quot;~{refGenome.ref_sa}&quot; .

    bwa mem \
      -p -v 3 -t 16 -M -R &#39;@RG\t~{read_group_id}\t~{sample_name}\t~{platform_info}&#39; \
      &quot;~{ref_fasta_local}&quot; &quot;~{input_fastq}&quot; &gt; &quot;~{base_file_name}.sam&quot; 
    samtools view -1bS -@ 15 -o &quot;~{base_file_name}.aligned.bam&quot; &quot;~{base_file_name}.sam&quot;
    samtools sort -@ 15 -o &quot;~{base_file_name}.sorted_query_aligned.bam&quot; &quot;~{base_file_name}.aligned.bam&quot;
  &gt;&gt;&gt;

  output {
    File analysisReadySorted = &quot;~{base_file_name}.sorted_query_aligned.bam&quot;
  }
  
  runtime {
    memory: &quot;48 GB&quot;
    cpu: 16
    docker: &quot;ghcr.io/getwilds/bwa:0.7.17&quot;
  }
}

# Mark duplicates on a BAM file
task MarkDuplicates {
  input {
    File input_bam
  }

  String base_file_name = basename(input_bam, &quot;.sorted_query_aligned.bam&quot;)

  command &lt;&lt;&lt;
    gatk MarkDuplicates \
      --INPUT &quot;~{input_bam}&quot; \
      --OUTPUT &quot;~{base_file_name}.duplicates_marked.bam&quot; \
      --METRICS_FILE &quot;~{base_file_name}.duplicate_metrics&quot; \
      --CREATE_INDEX true \
      --OPTICAL_DUPLICATE_PIXEL_DISTANCE 100 \
      --VALIDATION_STRINGENCY SILENT
  &gt;&gt;&gt;

  runtime {
    docker: &quot;ghcr.io/getwilds/gatk:4.3.0.0&quot;
    memory: &quot;48 GB&quot;
    cpu: 4
  }

  output {
    File markDuplicates_bam = &quot;~{base_file_name}.duplicates_marked.bam&quot;
    File markDuplicates_bai = &quot;~{base_file_name}.duplicates_marked.bai&quot;
    File duplicate_metrics = &quot;~{base_file_name}.duplicates_marked.bai&quot;
  }
}

# Base quality recalibration
task ApplyBaseRecalibrator {
  input {
    File input_bam
    File input_bam_index
    File dbSNP_vcf
    File dbSNP_vcf_index
    File known_indels_sites_VCFs
    File known_indels_sites_indices
    referenceGenome refGenome
  }
  
  String base_file_name = basename(input_bam, &quot;.duplicates_marked.bam&quot;)
  
  String ref_fasta_local = basename(refGenome.ref_fasta)
  String dbSNP_vcf_local = basename(dbSNP_vcf)
  String known_indels_sites_VCFs_local = basename(known_indels_sites_VCFs)


  command &lt;&lt;&lt;
  set -eo pipefail

  mv &quot;~{refGenome.ref_fasta}&quot; .
  mv &quot;~{refGenome.ref_fasta_index}&quot; .
  mv &quot;~{refGenome.ref_dict}&quot; .

  mv &quot;~{dbSNP_vcf}&quot; .
  mv &quot;~{dbSNP_vcf_index}&quot; .

  mv &quot;~{known_indels_sites_VCFs}&quot; .
  mv &quot;~{known_indels_sites_indices}&quot; .

  samtools index &quot;~{input_bam}&quot;

  gatk --java-options &quot;-Xms8g&quot; \
      BaseRecalibrator \
      -R &quot;~{ref_fasta_local}&quot; \
      -I &quot;~{input_bam}&quot; \
      -O &quot;~{base_file_name}.recal_data.csv&quot; \
      --known-sites &quot;~{dbSNP_vcf_local}&quot; \
      --known-sites &quot;~{known_indels_sites_VCFs_local}&quot; \
      

  gatk --java-options &quot;-Xms8g&quot; \
      ApplyBQSR \
      -bqsr &quot;~{base_file_name}.recal_data.csv&quot; \
      -I &quot;~{input_bam}&quot; \
      -O &quot;~{base_file_name}.recal.bam&quot; \
      -R &quot;~{ref_fasta_local}&quot; \
      

  # finds the current sort order of this bam file
  samtools view -H &quot;~{base_file_name}.recal.bam&quot; | grep @SQ | sed &#39;s/@SQ\tSN:\|LN://g&#39; &gt; &quot;~{base_file_name}.sortOrder.txt&quot;
  &gt;&gt;&gt;

  output {
    File recalibrated_bam = &quot;~{base_file_name}.recal.bam&quot;
    File recalibrated_bai = &quot;~{base_file_name}.recal.bai&quot;
    File sortOrder = &quot;~{base_file_name}.sortOrder.txt&quot;
  }
  runtime {
    memory: &quot;36 GB&quot;
    cpu: 2
    docker: &quot;ghcr.io/getwilds/gatk:4.3.0.0&quot;
  }
}

# Variant calling via mutect2 (tumor-and-normal mode)
task Mutect2Paired {
  input {
    File tumor_bam
    File tumor_bam_index
    File normal_bam
    File normal_bam_index
    referenceGenome refGenome
    File genomeReference
    File genomeReferenceIndex
  }

  String base_file_name_tumor = basename(tumor_bam, &quot;.recal.bam&quot;)
  String ref_fasta_local = basename(refGenome.ref_fasta)
  String genomeReference_local = basename(genomeReference)

  command &lt;&lt;&lt;
    set -eo pipefail

    mv &quot;~{refGenome.ref_fasta}&quot; .
    mv &quot;~{refGenome.ref_fasta_index}&quot; .
    mv &quot;~{refGenome.ref_dict}&quot; .

    mv &quot;~{genomeReference}&quot; .
    mv &quot;~{genomeReferenceIndex}&quot; .

    gatk --java-options &quot;-Xms16g&quot; Mutect2 \
      -R &quot;~{ref_fasta_local}&quot; \
      -I &quot;~{tumor_bam}&quot; \
      -I &quot;~{normal_bam}&quot; \
      -O preliminary.vcf.gz \
      --germline-resource &quot;~{genomeReference_local}&quot; \

    gatk --java-options &quot;-Xms16g&quot; FilterMutectCalls \
      -V preliminary.vcf.gz \
      -O &quot;~{base_file_name_tumor}.mutect2.vcf.gz&quot; \
      -R &quot;~{ref_fasta_local}&quot; \
      --stats preliminary.vcf.gz.stats \
  &gt;&gt;&gt;

  runtime {
    docker: &quot;ghcr.io/getwilds/gatk:4.3.0.0&quot;
    memory: &quot;24 GB&quot;
    cpu: 1
  }

  output {
    File output_vcf = &quot;${base_file_name_tumor}.mutect2.vcf.gz&quot;
    File output_vcf_index = &quot;${base_file_name_tumor}.mutect2.vcf.gz.tbi&quot;
  }
}

# Annotate VCF using annovar
task annovar {
  input {
    File input_vcf
    String ref_name
    String annovar_protocols
    String annovar_operation
  }
  String base_vcf_name = basename(input_vcf, &quot;.vcf.gz&quot;)
  
  command &lt;&lt;&lt;
    set -eo pipefail
  
    perl /annovar/table_annovar.pl &quot;~{input_vcf}&quot; /annovar/humandb/ \
      -buildver &quot;~{ref_name}&quot; \
      -outfile &quot;~{base_vcf_name}&quot; \
      -remove \
      -protocol &quot;~{annovar_protocols}&quot; \
      -operation &quot;~{annovar_operation}&quot; \
      -nastring . -vcfinput
  &gt;&gt;&gt;
  runtime {
    docker : &quot;ghcr.io/getwilds/annovar:${ref_name}&quot;
    cpu: 1
    memory: &quot;2GB&quot;
  }
  output {
    File output_annotated_vcf = &quot;~{base_vcf_name}.${ref_name}_multianno.vcf&quot;
    File output_annotated_table = &quot;~{base_vcf_name}.${ref_name}_multianno.txt&quot;
  }
}
</code></pre>
</details>
</div>
<div id="paired-tumor-normal-calling" class="section level2" number="7.3">
<h2><span class="header-section-number">7.3</span> Paired tumor normal calling</h2>
<p>Now that we are comfortable with task aliasing, we follow up with a more sophisticated tumor-normal matched somatic mutation calling in which each patient has unique paired tumor-normal samples. In order to do so, we need to ensure that each patient has an unique tumor and normal sample. We could modify our workflow inputs to be:</p>
<pre><code>workflow mutation_calling {
  input {
    Array[File] tumorSamples
    Array[file] normalSamples
    ...
  }
}</code></pre>
<p>but that would be a bit awkward to scatter through, as we would need to create a separate index to keep track of which sample we are using in the array of <code>tumorSamples</code> and <code>normalSamples</code>.</p>
<p>Instead, we write a struct for our paired samples:</p>
<pre><code>struct pairedSample {
  File tumorSample
  File normalSample
}</code></pre>
<p>so that in our workflow inputs, we use an array of <code>pairedSample</code>:</p>
<pre><code>workflow mutation_calling {
  input {
    Array[pairedSample] samples
    ...
  }
}</code></pre>
<p>and we can scatter on <code>samples</code>. Within our scatter, we use task aliasing to call tumor-specific and normal-specific tasks until <code>Mutect2Paired</code> and <code>annovar</code>.</p>
<pre><code>scatter (sample in samples) {

    #Tumors
    call BwaMem as tumorBwaMem {
      input:
        input_fastq = sample.tumorSample,
        refGenome = refGenome
    }

    #Normals
    call BwaMem as normalBwaMem {
      input:
        input_fastq = sample.normalSample,
        refGenome = refGenome
    }
    
    ...
   
}</code></pre>
<p>Putting it together:</p>
<pre><code>version 1.0
## WDL 101 example workflow
## 
## This WDL workflow is intended to be used along with the WDL 101 docs. 
## This workflow should be used for inspiration purposes only. 
##
## We use three samples 
## Samples:
## MOLM13: Normal sample
## CALU1: KRAS G12C mutant
## HCC4006: EGFR Ex19 deletion mutant 
##
## Input requirements:
## - combined fastq files for chromosome 12 and 7 +/- 200bp around the sites of mutation only
##
## Output Files:
## - An aligned bam for all 3 samples (with duplicates marked and base quality recalibrated)
## 
## Workflow developed by Sitapriya Moorthi, Chris Lo and Taylor Firman @ Fred Hutch and Ash (Aisling) O&#39;Farrell @ UCSC LMD: 02/28/24 for use @ Fred Hutch.

struct referenceGenome {
    File ref_fasta
    File ref_fasta_index
    File ref_dict
    File ref_amb
    File ref_ann
    File ref_bwt
    File ref_pac
    File ref_sa
    String ref_name
}

struct pairedSample {
  File tumorSample
  File normalSample
}


workflow mutation_calling {
  input {
    Array[pairedSample] samples

    referenceGenome refGenome
    
    # Files for specific tools
    File dbSNP_vcf
    File dbSNP_vcf_index
    File known_indels_sites_VCFs
    File known_indels_sites_indices
    File af_only_gnomad
    File af_only_gnomad_index

    # Annovar options
    String annovar_protocols
    String annovar_operation
  }

 
  # Scatter for each sample in samples
  scatter (sample in samples) {

    #Tumors
    call BwaMem as tumorBwaMem {
      input:
        input_fastq = sample.tumorSample,
        refGenome = refGenome
    }
    
    call MarkDuplicates as tumorMarkDuplicates {
      input:
        input_bam = tumorBwaMem.analysisReadySorted
    }

    call ApplyBaseRecalibrator as tumorApplyBaseRecalibrator{
      input:
        input_bam = tumorMarkDuplicates.markDuplicates_bam,
        input_bam_index = tumorMarkDuplicates.markDuplicates_bai,
        dbSNP_vcf = dbSNP_vcf,
        dbSNP_vcf_index = dbSNP_vcf_index,
        known_indels_sites_VCFs = known_indels_sites_VCFs,
        known_indels_sites_indices = known_indels_sites_indices,
        refGenome = refGenome
    }

    #Normals
    call BwaMem as normalBwaMem {
      input:
        input_fastq = sample.normalSample,
        refGenome = refGenome
    }
    
    call MarkDuplicates as normalMarkDuplicates {
      input:
        input_bam = normalBwaMem.analysisReadySorted
    }
  
    call ApplyBaseRecalibrator as normalApplyBaseRecalibrator {
      input:
        input_bam = normalMarkDuplicates.markDuplicates_bam,
        input_bam_index = normalMarkDuplicates.markDuplicates_bai,
        dbSNP_vcf = dbSNP_vcf,
        dbSNP_vcf_index = dbSNP_vcf_index,
        known_indels_sites_VCFs = known_indels_sites_VCFs,
        known_indels_sites_indices = known_indels_sites_indices,
        refGenome = refGenome
    }

    #Paired Tumor-Normal calling
    call Mutect2Paired {
      input:
        tumor_bam = tumorApplyBaseRecalibrator.recalibrated_bam,
        tumor_bam_index = tumorApplyBaseRecalibrator.recalibrated_bai,
        normal_bam = normalApplyBaseRecalibrator.recalibrated_bam,
        normal_bam_index = normalApplyBaseRecalibrator.recalibrated_bai,
        refGenome = refGenome,
        genomeReference = af_only_gnomad,
        genomeReferenceIndex = af_only_gnomad_index
    }

    call annovar {
      input:
        input_vcf = Mutect2Paired.output_vcf,
        ref_name = refGenome.ref_name,
        annovar_operation = annovar_operation,
        annovar_protocols = annovar_protocols
    }
}

  output {
    Array[File] tumoralignedBamSorted = tumorBwaMem.analysisReadySorted
    Array[File] tumorMarkDuplicates_bam = tumorMarkDuplicates.markDuplicates_bam
    Array[File] tumorMarkDuplicates_bai = tumorMarkDuplicates.markDuplicates_bai
    Array[File] tumoranalysisReadyBam = tumorApplyBaseRecalibrator.recalibrated_bam 
    Array[File] tumoranalysisReadyIndex = tumorApplyBaseRecalibrator.recalibrated_bai
    Array[File] normalalignedBamSorted = normalBwaMem.analysisReadySorted
    Array[File] normalmarkDuplicates_bam = normalMarkDuplicates.markDuplicates_bam
    Array[File] normalmarkDuplicates_bai = normalMarkDuplicates.markDuplicates_bai
    Array[File] normalanalysisReadyBam = normalApplyBaseRecalibrator.recalibrated_bam 
    Array[File] normalanalysisReadyIndex = normalApplyBaseRecalibrator.recalibrated_bai
    Array[File] Mutect2Paired_Vcf = Mutect2Paired.output_vcf
    Array[File] Mutect2Paired_VcfIndex = Mutect2Paired.output_vcf_index
    Array[File] Mutect2Paired_AnnotatedVcf = annovar.output_annotated_vcf
    Array[File] Mutect2Paired_AnnotatedTable = annovar.output_annotated_table
  }

  parameter_meta {
    tumorSamples: &quot;Tumor .fastq, one sample per .fastq file (expects Illumina)&quot;
    normalFastq: &quot;Non-tumor .fastq (expects Illumina)&quot;

    dbSNP_vcf: &quot;dbSNP VCF for mutation calling&quot;
    dbSNP_vcf_index: &quot;dbSNP VCF index&quot;
    known_indels_sites_VCFs: &quot;Known indel site VCF for mutation calling&quot;
    known_indels_sites_indices: &quot;Known indel site VCF indicies&quot;
    af_only_gnomad: &quot;gnomAD population allele fraction for mutation calling&quot;
    af_only_gnomad_index: &quot;gnomAD population allele fraction index&quot;

    annovar_protocols: &quot;annovar protocols: see https://annovar.openbioinformatics.org/en/latest/user-guide/startup&quot;
    annovar_operation: &quot;annovar operation: see https://annovar.openbioinformatics.org/en/latest/user-guide/startup&quot;
  }
}

####################
# Task definitions #
####################

# Align fastq file to the reference genome
task BwaMem {
  input {
    File input_fastq
    referenceGenome refGenome
  }
  
  String base_file_name = basename(input_fastq, &quot;.fastq&quot;)
  String ref_fasta_local = basename(refGenome.ref_fasta)

  String read_group_id = &quot;ID:&quot; + base_file_name
  String sample_name = &quot;SM:&quot; + base_file_name
  String platform_info = &quot;PL:illumina&quot;


  command &lt;&lt;&lt;
    set -eo pipefail

    mv &quot;~{refGenome.ref_fasta}&quot; .
    mv &quot;~{refGenome.ref_fasta_index}&quot; .
    mv &quot;~{refGenome.ref_dict}&quot; .
    mv &quot;~{refGenome.ref_amb}&quot; .
    mv &quot;~{refGenome.ref_ann}&quot; .
    mv &quot;~{refGenome.ref_bwt}&quot; .
    mv &quot;~{refGenome.ref_pac}&quot; .
    mv &quot;~{refGenome.ref_sa}&quot; .

    bwa mem \
      -p -v 3 -t 16 -M -R &#39;@RG\t~{read_group_id}\t~{sample_name}\t~{platform_info}&#39; \
      &quot;~{ref_fasta_local}&quot; &quot;~{input_fastq}&quot; &gt; &quot;~{base_file_name}.sam&quot; 
    samtools view -1bS -@ 15 -o &quot;~{base_file_name}.aligned.bam&quot; &quot;~{base_file_name}.sam&quot;
    samtools sort -@ 15 -o &quot;~{base_file_name}.sorted_query_aligned.bam&quot; &quot;~{base_file_name}.aligned.bam&quot;
  &gt;&gt;&gt;

  output {
    File analysisReadySorted = &quot;~{base_file_name}.sorted_query_aligned.bam&quot;
  }
  
  runtime {
    memory: &quot;48 GB&quot;
    cpu: 16
    docker: &quot;ghcr.io/getwilds/bwa:0.7.17&quot;
  }
}

# Mark duplicates on a BAM file
task MarkDuplicates {
  input {
    File input_bam
  }

  String base_file_name = basename(input_bam, &quot;.sorted_query_aligned.bam&quot;)

  command &lt;&lt;&lt;
    gatk MarkDuplicates \
      --INPUT &quot;~{input_bam}&quot; \
      --OUTPUT &quot;~{base_file_name}.duplicates_marked.bam&quot; \
      --METRICS_FILE &quot;~{base_file_name}.duplicate_metrics&quot; \
      --CREATE_INDEX true \
      --OPTICAL_DUPLICATE_PIXEL_DISTANCE 100 \
      --VALIDATION_STRINGENCY SILENT
  &gt;&gt;&gt;

  runtime {
    docker: &quot;ghcr.io/getwilds/gatk:4.3.0.0&quot;
    memory: &quot;48 GB&quot;
    cpu: 4
  }

  output {
    File markDuplicates_bam = &quot;~{base_file_name}.duplicates_marked.bam&quot;
    File markDuplicates_bai = &quot;~{base_file_name}.duplicates_marked.bai&quot;
    File duplicate_metrics = &quot;~{base_file_name}.duplicates_marked.bai&quot;
  }
}

# Base quality recalibration
task ApplyBaseRecalibrator {
  input {
    File input_bam
    File input_bam_index
    File dbSNP_vcf
    File dbSNP_vcf_index
    File known_indels_sites_VCFs
    File known_indels_sites_indices
    referenceGenome refGenome
  }
  
  String base_file_name = basename(input_bam, &quot;.duplicates_marked.bam&quot;)
  
  String ref_fasta_local = basename(refGenome.ref_fasta)
  String dbSNP_vcf_local = basename(dbSNP_vcf)
  String known_indels_sites_VCFs_local = basename(known_indels_sites_VCFs)


  command &lt;&lt;&lt;
  set -eo pipefail

  mv &quot;~{refGenome.ref_fasta}&quot; .
  mv &quot;~{refGenome.ref_fasta_index}&quot; .
  mv &quot;~{refGenome.ref_dict}&quot; .

  mv &quot;~{dbSNP_vcf}&quot; .
  mv &quot;~{dbSNP_vcf_index}&quot; .

  mv &quot;~{known_indels_sites_VCFs}&quot; .
  mv &quot;~{known_indels_sites_indices}&quot; .

  samtools index &quot;~{input_bam}&quot;

  gatk --java-options &quot;-Xms8g&quot; \
      BaseRecalibrator \
      -R &quot;~{ref_fasta_local}&quot; \
      -I &quot;~{input_bam}&quot; \
      -O &quot;~{base_file_name}.recal_data.csv&quot; \
      --known-sites &quot;~{dbSNP_vcf_local}&quot; \
      --known-sites &quot;~{known_indels_sites_VCFs_local}&quot; \
      

  gatk --java-options &quot;-Xms8g&quot; \
      ApplyBQSR \
      -bqsr &quot;~{base_file_name}.recal_data.csv&quot; \
      -I &quot;~{input_bam}&quot; \
      -O &quot;~{base_file_name}.recal.bam&quot; \
      -R &quot;~{ref_fasta_local}&quot; \
      

  # finds the current sort order of this bam file
  samtools view -H &quot;~{base_file_name}.recal.bam&quot; | grep @SQ | sed &#39;s/@SQ\tSN:\|LN://g&#39; &gt; &quot;~{base_file_name}.sortOrder.txt&quot;
  &gt;&gt;&gt;

  output {
    File recalibrated_bam = &quot;~{base_file_name}.recal.bam&quot;
    File recalibrated_bai = &quot;~{base_file_name}.recal.bai&quot;
    File sortOrder = &quot;~{base_file_name}.sortOrder.txt&quot;
  }
  runtime {
    memory: &quot;36 GB&quot;
    cpu: 2
    docker: &quot;ghcr.io/getwilds/gatk:4.3.0.0&quot;
  }
}

# Variant calling via mutect2 (tumor-and-normal mode)
task Mutect2Paired {
  input {
    File tumor_bam
    File tumor_bam_index
    File normal_bam
    File normal_bam_index
    referenceGenome refGenome
    File genomeReference
    File genomeReferenceIndex
  }

  String base_file_name_tumor = basename(tumor_bam, &quot;.recal.bam&quot;)
  String ref_fasta_local = basename(refGenome.ref_fasta)
  String genomeReference_local = basename(genomeReference)

  command &lt;&lt;&lt;
    set -eo pipefail

    mv &quot;~{refGenome.ref_fasta}&quot; .
    mv &quot;~{refGenome.ref_fasta_index}&quot; .
    mv &quot;~{refGenome.ref_dict}&quot; .

    mv &quot;~{genomeReference}&quot; .
    mv &quot;~{genomeReferenceIndex}&quot; .

    gatk --java-options &quot;-Xms16g&quot; Mutect2 \
      -R &quot;~{ref_fasta_local}&quot; \
      -I &quot;~{tumor_bam}&quot; \
      -I &quot;~{normal_bam}&quot; \
      -O preliminary.vcf.gz \
      --germline-resource &quot;~{genomeReference_local}&quot; \

    gatk --java-options &quot;-Xms16g&quot; FilterMutectCalls \
      -V preliminary.vcf.gz \
      -O &quot;~{base_file_name_tumor}.mutect2.vcf.gz&quot; \
      -R &quot;~{ref_fasta_local}&quot; \
      --stats preliminary.vcf.gz.stats \
  &gt;&gt;&gt;

  runtime {
    docker: &quot;ghcr.io/getwilds/gatk:4.3.0.0&quot;
    memory: &quot;24 GB&quot;
    cpu: 1
  }

  output {
    File output_vcf = &quot;${base_file_name_tumor}.mutect2.vcf.gz&quot;
    File output_vcf_index = &quot;${base_file_name_tumor}.mutect2.vcf.gz.tbi&quot;
  }
}

# Annotate VCF using annovar
task annovar {
  input {
    File input_vcf
    String ref_name
    String annovar_protocols
    String annovar_operation
  }
  String base_vcf_name = basename(input_vcf, &quot;.vcf.gz&quot;)
  
  command &lt;&lt;&lt;
    set -eo pipefail
  
    perl annovar/table_annovar.pl &quot;~{input_vcf}&quot; annovar/humandb/ \
      -buildver &quot;~{ref_name}&quot; \
      -outfile &quot;~{base_vcf_name}&quot; \
      -remove \
      -protocol &quot;~{annovar_protocols}&quot; \
      -operation &quot;~{annovar_operation}&quot; \
      -nastring . -vcfinput
  &gt;&gt;&gt;
  runtime {
    docker: &quot;ghcr.io/getwilds/annovar:~{ref_name}&quot;
    cpu: 1
    memory: &quot;2GB&quot;
  }
  output {
    File output_annotated_vcf = &quot;~{base_vcf_name}.${ref_name}_multianno.vcf&quot;
    File output_annotated_table = &quot;~{base_vcf_name}.${ref_name}_multianno.txt&quot;
  }
}</code></pre>
<p>The JSON metadata:</p>
<pre><code>{
  &quot;mutation_calling.samples&quot;: [{&quot;tumorSample&quot;: &quot;/path/to/Tumor_1_KRAS_CALU1_combined_final.fastq&quot;,
                                &quot;normalSample&quot;: &quot;/path/to/Normal_1_MOLM13_combined_final.fastq&quot;},
                               {&quot;tumorSample&quot;: &quot;/path/to/Tumor_2_EGFR_HCC4006_combined.fastq&quot;,
                                &quot;normalSample&quot;: &quot;/path/to/Normal_2_MOLM13_combined_final.fastq&quot;}],
  &quot;mutation_calling.refGenome&quot;: {
    &quot;ref_fasta&quot;: &quot;/path/to/Homo_sapiens_assembly19.fasta&quot;,
    &quot;ref_fasta_index&quot;: &quot;/path/to/Homo_sapiens_assembly19.fasta.fai&quot;,
    &quot;ref_dict&quot;: &quot;/path/to/Homo_sapiens_assembly19.dict&quot;,
    &quot;ref_pac&quot;: &quot;/path/to/Homo_sapiens_assembly19.fasta.pac&quot;,
    &quot;ref_sa&quot;: &quot;/path/to/Homo_sapiens_assembly19.fasta.sa&quot;,
    &quot;ref_amb&quot;: &quot;/path/to/Homo_sapiens_assembly19.fasta.amb&quot;,
    &quot;ref_ann&quot;: &quot;/path/to/Homo_sapiens_assembly19.fasta.ann&quot;,
    &quot;ref_bwt&quot;: &quot;/path/to/Homo_sapiens_assembly19.fasta.bwt&quot;,
    &quot;ref_name&quot;: &quot;hg19&quot;
  },
  &quot;mutation_calling.dbSNP_vcf_index&quot;: &quot;/path/to/dbsnp_138.b37.vcf.gz.tbi&quot;,
  &quot;mutation_calling.dbSNP_vcf&quot;: &quot;/path/to/dbsnp_138.b37.vcf.gz&quot;,
  &quot;mutation_calling.known_indels_sites_indices&quot;: &quot;/path/to/Mills_and_1000G_gold_standard.indels.b37.sites.vcf.idx&quot;,
  &quot;mutation_calling.known_indels_sites_VCFs&quot;: &quot;/path/to/Mills_and_1000G_gold_standard.indels.b37.sites.vcf&quot;,
  &quot;mutation_calling.af_only_gnomad&quot;: &quot;/path/to/af-only-gnomad.raw.sites.b37.vcf.gz&quot;,
  &quot;mutation_calling.af_only_gnomad_index&quot;: &quot;/path/to/af-only-gnomad.raw.sites.b37.vcf.gz.tbi&quot;,
  &quot;mutation_calling.annovar_protocols&quot;: &quot;refGene,knownGene,cosmic70,esp6500siv2_all,clinvar_20180603,gnomad211_exome&quot;,
  &quot;mutation_calling.annovar_operation&quot;: &quot;g,f,f,f,f,f&quot;
}</code></pre>
<details>
<summary>
<b>The JSON using the Fred Hutch HPC</b>
</summary>
<pre><code>{
  &quot;mutation_calling.sampleFastq&quot;: &quot;/fh/fast/paguirigan_a/pub/ReferenceDataSets/workflow_testing_data/WDL/wdl_101/HCC4006_final.fastq&quot;,
  &quot;mutation_calling.ref_fasta&quot;: &quot;/fh/fast/paguirigan_a/pub/ReferenceDataSets/genome_data/human/hg19/Homo_sapiens_assembly19.fasta&quot;,
  &quot;mutation_calling.ref_fasta_index&quot;: &quot;/fh/fast/paguirigan_a/pub/ReferenceDataSets/genome_data/human/hg19/Homo_sapiens_assembly19.fasta.fai&quot;,
  &quot;mutation_calling.ref_dict&quot;: &quot;/fh/fast/paguirigan_a/pub/ReferenceDataSets/genome_data/human/hg19/Homo_sapiens_assembly19.dict&quot;,
  &quot;mutation_calling.ref_pac&quot;: &quot;/fh/fast/paguirigan_a/pub/ReferenceDataSets/genome_data/human/hg19/Homo_sapiens_assembly19.fasta.pac&quot;,
  &quot;mutation_calling.ref_sa&quot;: &quot;/fh/fast/paguirigan_a/pub/ReferenceDataSets/genome_data/human/hg19/Homo_sapiens_assembly19.fasta.sa&quot;,
  &quot;mutation_calling.ref_amb&quot;: &quot;/fh/fast/paguirigan_a/pub/ReferenceDataSets/genome_data/human/hg19/Homo_sapiens_assembly19.fasta.amb&quot;,
  &quot;mutation_calling.ref_ann&quot;: &quot;/fh/fast/paguirigan_a/pub/ReferenceDataSets/genome_data/human/hg19/Homo_sapiens_assembly19.fasta.ann&quot;,
  &quot;mutation_calling.ref_bwt&quot;: &quot;/fh/fast/paguirigan_a/pub/ReferenceDataSets/genome_data/human/hg19/Homo_sapiens_assembly19.fasta.bwt&quot;,
  &quot;mutation_calling.ref_name&quot;: &quot;hg19&quot;,
  &quot;mutation_calling.dbSNP_vcf_index&quot;: &quot;/fh/fast/paguirigan_a/pub/ReferenceDataSets/genome_data/human/hg19/dbsnp_138.b37.vcf.gz.tbi&quot;,
  &quot;mutation_calling.dbSNP_vcf&quot;: &quot;/fh/fast/paguirigan_a/pub/ReferenceDataSets/genome_data/human/hg19/dbsnp_138.b37.vcf.gz&quot;,
  &quot;mutation_calling.known_indels_sites_indices&quot;: &quot;/fh/fast/paguirigan_a/pub/ReferenceDataSets/genome_data/human/hg19/Mills_and_1000G_gold_standard.indels.b37.sites.vcf.idx&quot;,
  &quot;mutation_calling.known_indels_sites_VCFs&quot;: &quot;/fh/fast/paguirigan_a/pub/ReferenceDataSets/genome_data/human/hg19/Mills_and_1000G_gold_standard.indels.b37.sites.vcf&quot;,
  &quot;mutation_calling.af_only_gnomad&quot;: &quot;/fh/fast/paguirigan_a/pub/ReferenceDataSets/genome_data/human/hg19/af-only-gnomad.raw.sites.b37.vcf.gz&quot;,
  &quot;mutation_calling.af_only_gnomad_index&quot;: &quot;/fh/fast/paguirigan_a/pub/ReferenceDataSets/genome_data/human/hg19/af-only-gnomad.raw.sites.b37.vcf.gz.tbi&quot;,
  &quot;mutation_calling.annovar_protocols&quot;: &quot;refGene,knownGene,cosmic70,esp6500siv2_all,clinvar_20180603,gnomad211_exome&quot;,
  &quot;mutation_calling.annovar_operation&quot;: &quot;g,f,f,f,f,f&quot;
}</code></pre>
</details>
<p>Now we have a complete workflow that reflects our original plan in <a href="https://hutchdatascience.org/WDL_Workflows_Guide/defining-a-workflow-plan.html">Defining a workflow plan</a>!</p>
<iframe src="https://docs.google.com/forms/d/e/1FAIpQLSeEKGWTJOowBhFlWftPUjFU8Rfj-d9iXIHENyd8_HGS8PM7kw/viewform?embedded=true" width="640" height="886" frameborder="0" marginheight="0" marginwidth="0">
Loading…
</iframe>

</div>
</div>
<hr>
<center> 
  <div class="footer">
      All illustrations <a href="https://creativecommons.org/licenses/by/4.0/">CC-BY. </a>
      <br>
      All other materials <a href= "https://creativecommons.org/licenses/by/4.0/"> CC-BY </a> unless noted otherwise.
      <a href="https://hutchdatascience.org/" target="_blank"><img src="https://hutchdatascience.org/images/crazy-idea-wide.png" style="width: 80%; padding-left: 15px; padding-top: 8px;"</a>
  </div>
</center>
            </section>

          </div>
        </div>
      </div>
<a href="parallelization-via-arrays.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="optional-types.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "section"
}
});
});
</script>

</body>

</html>

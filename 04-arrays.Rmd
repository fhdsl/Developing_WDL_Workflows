```{r, include = FALSE}
ottrpal::set_knitr_image_path()
```

# Using Arrays For Parallelization and Other Use Cases

We have a workflow that runs on a single sample. What if we want to process multiple samples at once? Let's look at the various ways we can run our workflow more efficiently, as well as processing many samples in parallel. This is where WDL really shines.

- How to use scattered tasks to run a workflow on multiple samples at once
- How to use arrays effectively
- How to reference arrays in a task's command section
- How arrays differ from Structs

## The array type





## Referencing an array in a task

If the input variable is an array, we must include an array separator. In WDL 1.0, this is done using the `sep=` expression placeholder. Every value in the WDL Array[String] will be separated by whatever value is declared via `sep`. In this example, that is a simple space, as that is one way how to construct a bash variable.

```
task count_words {
  input {
    Array[String] a_big_sentence
  }
  command <<<
    ARRAY_OF_WORDS=(~{sep=" " a_big_sentence})
    echo ${#ARRAY_OF_FILES[@]} >> length.txt
    # Note how the bash array uses ${} syntax, which could quickly get
    # confusing if we used that syntax for our WDL variables. This is
    # why we recommend using tilde + {} for your WDL variables.
  >>>
}
```
It's usually unnecessary to declare an Array[String], because a single String can have many words in it. That being said, an Array[String] can sometimes come in handy if it is made up of outputs from other tasks. We'll talk more about chaining tasks together in upcoming chapters.

::: {.notice data-latex="warning"}
The WDL 1.1 spec added a new built-in function, `sep()`, which replaces the `sep=` expression placeholder for arrays. This same version of the spec also notes that the `sep=` expression placeholder [are deprecated and will be removed from future versions of WDL](https://github.com/openwdl/wdl/blob/main/versions/1.1/SPEC.md#-expression-placeholder-options). For the time being, we recommend sticking with `sep=` as it is compatible with both WDL 1.0 and WDL 1.1, even though it is technically deprecated in WDL 1.1.
:::

If you're not used to working in bash, the syntax for interacting with bash arrays can be unintuitive, but you don't have to write a WDL's command section only using bash. In fact, working in another language besides bash within a WDL can be a great way to write code quickly, or perform tasks that are more advanced than what a typical bash script can handle. Just be sure to set `sep` properly to ensure that your array is interpreted correctly. In this example, we place quotation marks before and after the variable to ensure that the first and last value of the list are given beginning and ending quotation marks respectively.

```
task count_words_python {
  input {
    Array[String] a_big_sentence
  }
  command <<<
    python << CODE
    sentence = [ "~{sep='", "' a_big_sentence}" ]
    print(len(sentence))
    CODE
  >>>
  runtime {
    docker: "python:latest"
  }
}
```





## Scattered tasks

### Troubleshooting
Scattered tasks are relatively simple in theory, but the way they interact with optional types can be unintutive. If you are running into issues running scattered tasks on optional types, please see the section on optional types. As a general rule, you should avoid using optional types as the input of a scattered task whenever possible.

Generally speaking, a WDL executor will try to run as many instances of a scattered task as it thinks your backend's hardware can handle at once. Sometimes the WDL executor will overestimate what the backend is capable of and run too many instances of a scattered task at once. This almost never happens on scaleable cloud-based backends such as Terra, but isn't uncommon when running scattered tasks on a local machine. For advice on diagnosising this issue and how to prevent it, please see the optimization chapter of this course.

## Making our workflow run on multiple samples at once




## Nested arrays
Our workflow assumes that every sample has a single fastq file, such as `SRR8618962.fastq`. However, fastq files are sometimes split by read direction, resulting in `SRR8618962_1.fastq` and `SRR8618962_2.fastq`. How would we modify our workflow to accept this sort of input, and still be able to run on multiple samples at once?

The first thing to keep in mind is that we no longer represent a single sample as a single `File sampleFastq`, but instead as `Array[File] sampleFastqs`. In real life, fastq files may be split even further than `_1` and `_2`, such as by which lane of an Illumina cell they were sequenced in. The same concept we will go over here can be applied to multilane samples too, but for now we will focus on the `_1` and `_2` case for simplicity. This means that each sample is an array with precisely two values.

Our first step in the workflow is bwa mem, which changes a single sample's fastq file(s) into a single bam file. No matter how many fastqs we input for a single sample, we will always end up with just one bam file to represent that sample. That means that, for this workflow in particular, we only need to change the first task.


TODO: edits of bwa call


Modifying our workflow to run on multiple samples requires the use of nested arrays. Our workflow-level input `Array[File] sampleFastqs` needs to become `Array[Array[File]] allSampleFastqs`. Each internal array represents a pair of fastqs, which we could enter via JSON like so:

```
"minidata_mutation_calling_v1.allSampleFastqs": [
    ["/fh/scratch/delete90/_DaSL/WDL_mini_data/NCIH2172_LUNG/SRR8618962_1.fastq", "/fh/scratch/delete90/_DaSL/WDL_mini_data/NCIH2172_LUNG/SRR8618962_2.fastq"],
    ["/fh/scratch/delete90/_DaSL/WDL_mini_data/NA12878_Broad/H06JUADXX130110.1.ATCACGAT.20k_interleaved_1.fastq", "/fh/scratch/delete90/_DaSL/WDL_mini_data/NA12878_Broad/H06JUADXX130110.1.ATCACGAT.20k_interleaved_2.fastq"]]
```
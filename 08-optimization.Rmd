```{r, include = FALSE}
ottrpal::set_knitr_image_path()
```

# Optimizing Workflows

- How to use scattered tasks to make analysis more efficient
- Diagnosising and treating the most common issues stemming from inefficient workflow setup
- An introduction to controlling costs on cloud compute backends
- How to automatically scale disk size runtime attributes based on the size of a task's inputs
- How to stop Cromwell from trying to launch dozens of instances of a scattered task at once (and why you may want it to that!)




## Scattered tasks: A reintroduction
In chapter 6, we introduced arrays and scattered tasks. Scattered tasks were brought up in the context of running multiple samples at the same time. However, they can also be used to run parts of a single sample at the same time. This is especially useful in the world of human genomics, as chromosomes provide the perfect opportunity to split your data into discrete portions.

When splitting by chromosome, instead of running (for example) a variant caller in a single Docker image, we are launching 23 instances of the variant caller in 23 Docker images. As a result, this sort of optimization is not ideal for all backends -- if you are limited by the number of Docker containers you can run at any given (typically the case on a local compute), then splitting by chromosome is unlikely to make the overall workflow more efficient.


## Splitting by chromosome



We don't need to decide between making our workflow multi-sample or multi-chromosome. We can do both using nested arrays, but beware: Depending on how you WDL executor and backend is set up, this could result in dozens of Docker images running at the same time. For highly scalable backends or executors with a good handle of available compute resources, this is desirable. For a more limited machine, this could be disastrous.


## Troubleshooting

### Running out of memory
A task that has run out of memory will typically have a [return code](https://en.wikipedia.org/wiki/Error_code) of 137. In some WDL executors, you will find a file called `rc` for each completed task which contains a single integer representing that task's return code. This code might also be printed on the command line or the workflow's overall logs. Depending on what tool you are running in the task, you may also see something like "out of memory" in stderr or stdout.

(Strictly speaking, a return code of 137 is SIGKILL, meaning the operating system forcibly shut down a task. For the purposes of WDL, this almost always means running out memory, but in other contexts it may have other causes.)

#### Special case: samtools
If your task involves samtools and you see something like `samtools sort: couldn't allocate memory for bam_mem`, this may be caused by setting up the samtools call incorrectly. Pay attention to how many threads you are requesting (`-t`/`--threads`) and how memory you are requesting per each of those threads (`-m`).

### Running out of disk space

### Docker lockup
As of February 2024, the authors of this course have only seen this behavior happen on Cromwell. However, it is theoretically possible it could happen on miniwdl.



Possible solutions include:

* Modifying the Cromwell configuration file to only run one task at a time

* Switching to miniwdl

* Switching a backend that can reliably scale on scattered tasks



### Very large scatters ( >100x)
* Even Terra has its limitations. As of February 2024, Terra's Task Manager UI starts to break down when scattering more than 200x. Around 1000x, the chances of a task failing to initialize increases, which may cause the overall workflow to report a failure (rerunning the workflow with call cacheing enabled will generally bypass the issue).